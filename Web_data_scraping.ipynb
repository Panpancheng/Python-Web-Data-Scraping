{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Data Scraping\n",
    "\n",
    "Website:http://www.landofbasketball.com/results/2014_2015_scores.htm\n",
    "\n",
    "We need to scrape data and put into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st_away</th>\n",
       "      <th>1st_home</th>\n",
       "      <th>2st_away</th>\n",
       "      <th>2st_home</th>\n",
       "      <th>3st_away</th>\n",
       "      <th>3st_home</th>\n",
       "      <th>4th_away</th>\n",
       "      <th>4th_home</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_team</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first row</th>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>LAC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>January</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1st_away 1st_home 2st_away 2st_home 3st_away 3st_home 4th_away  \\\n",
       "first row       30       21       28       19       27       35       30   \n",
       "\n",
       "          4th_home away_team home_team    month season  \n",
       "first row       30       LAC       ATL  January   2017  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need information of teams, scores, date \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the library used to query a website\n",
    "import urllib2\n",
    "#import the Beautiful soup functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import string\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.landofbasketball.com/results/2014_2015_may_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_mar_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_jan_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_apr_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_jun_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_oct_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_scores_full.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_nov_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_feb_scores.htm\n",
      "http://www.landofbasketball.com/results/2014_2015_dec_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_nov_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_mar_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_oct_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_may_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_jun_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_jan_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_feb_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_dec_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_apr_scores.htm\n",
      "http://www.landofbasketball.com/results/2015_2016_scores_full.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_oct_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_scores_full.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_nov_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_feb_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_dec_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_may_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_jun_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_mar_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_jan_scores.htm\n",
      "http://www.landofbasketball.com/results/2016_2017_apr_scores.htm\n",
      "7184\n"
     ]
    }
   ],
   "source": [
    "year_time = [\"2014_2015\",\"2015_2016\",\"2016_2017\"]\n",
    "wiki_origins =[\"http://www.landofbasketball.com/results/2014_2015_scores.htm\",\"http://www.landofbasketball.com/results/2015_2016_scores.htm\",\"http://www.landofbasketball.com/results/2016_2017_scores.htm\"]\n",
    "#whole_data = []\n",
    "#data_fields =[\"season\", \"month\", \"away_team\",\"home_team\", \"1st_away\",\"1st_home\",\"2st_away\",\"2st_home\",\"3st_away\", \"3st_home\",\"4th_away\",\"4th_home\"]\n",
    "output_data = pd.DataFrame()\n",
    "for i in range(len(wiki_origins)):\n",
    "    wiki_origin = wiki_origins[i]\n",
    "    #print wiki_origin\n",
    "    page_home = urllib2.urlopen(wiki_origin)\n",
    "    #Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "    soup_home = BeautifulSoup(page_home)\n",
    "    soup_home.find_all('a')\n",
    "    #Use function “prettify” to look at nested structure of HTML page\n",
    "    month_list = soup_home.find_all(href=re.compile(\"^\"+year_time[i]))\n",
    "    month_list\n",
    "    month_list_links = [a.attrs.get('href') for a in month_list]\n",
    "    root_url = \"http://www.landofbasketball.com/results/\"\n",
    "    second_link = [root_url + month_list_links[a] for a in range(len(month_list_links))]\n",
    "    second_link = list(set(second_link))\n",
    "    #'http://www.landofbasketball.com/results/2014_2015_may_scores.htm'\n",
    "    for j in range(len(second_link)):\n",
    "        wiki = second_link[j]\n",
    "        print wiki\n",
    "        page = urllib2.urlopen(wiki)\n",
    "        #Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "        soup = BeautifulSoup(page)\n",
    "        #Use function “prettify” to look at nested structure of HTML page\n",
    "        #soup.find_all(href=re.compile(\"box_scores\"))\n",
    "        #only need child websites starts with box_scores\n",
    "        quarter_list = soup.find_all(href=re.compile(\"box_scores\"))\n",
    "        links = [a.attrs.get('href') for a in quarter_list]\n",
    "        #links\n",
    "        root_url = \"http://www.landofbasketball.com\"\n",
    "        #print len(links)\n",
    "        a = 0\n",
    "        for a in range(len(links)):\n",
    "            links[a] = links[a].replace(\"..\", \"\") \n",
    "            a += 1\n",
    "        #print links[0]\n",
    "        quarter_2014 = [root_url + links[a] for a in range(len(links))]\n",
    "        quarter_2014_deduplicate = list(set(quarter_2014))\n",
    "        #we will get the website: http://www.landofbasketball.com/box_scores/2014/1028ORLNOP.htm\n",
    "        for m in range(len(quarter_2014_deduplicate)):\n",
    "            page = urllib2.urlopen(quarter_2014_deduplicate[m])\n",
    "            #print page\n",
    "            soup = BeautifulSoup(page)\n",
    "            #find right tables\n",
    "            score_table = soup.find(\"div\", {\"class\": \"rd-100-50 margen-b6 margen-b3\"})\n",
    "            if score_table is None:\n",
    "                continue\n",
    "            A = []\n",
    "            for row in score_table.findAll(\"tr\"):\n",
    "                cells = row.findAll('td')\n",
    "                cols = [ele.text.strip() for ele in cells]\n",
    "                A.append([ele for ele in cols if ele])\n",
    "            #print A\n",
    "            #################\n",
    "            score_table2 = soup.find(\"div\", {\"class\": \"rd-100-30 margen-b6 clearfix\"})\n",
    "            if score_table2 is None:\n",
    "                continue\n",
    "            A2= []\n",
    "            for row in score_table2.findAll(\"p\"):\n",
    "                #print row\n",
    "                text = row.text.strip()\n",
    "                text = text.split(\": \",1)[1]\n",
    "                #print text\n",
    "                A2.append(text)\n",
    "            date = str(A2[0])\n",
    "            month = date.split(\" \",1)[0]\n",
    "            #print month\n",
    "            season = date.split(\",\",1)[1]\n",
    "            #print season\n",
    "            hometeam =  str(A2[1])\n",
    "            #print hometeam\n",
    "            score_table3 = soup.find(\"div\", {\"class\": \"rd-tbl-2\"})\n",
    "            A3 = []\n",
    "            for row in score_table3.findAll(\"tr\"):\n",
    "                cells = row.findAll('td')\n",
    "                cols = [ele.text.strip() for ele in cells]\n",
    "                A3.append([ele for ele in cols if ele])\n",
    "            away_team_temp= str(A3[0][0])\n",
    "            #home_team_temp= str(A3[20][0])\n",
    "            away_team = \" \".join(re.findall(\"[a-zA-Z]+\", away_team_temp))\n",
    "            #home_team = \" \".join(re.findall(\"[a-zA-Z]+\", home_team_temp))\n",
    "            d={}\n",
    "            df=pd.DataFrame()\n",
    "            if A[1][0].lower() in hometeam.lower():\n",
    "                #whole_data.append([season,month,away_team,home_team,A[2][1],A[1][1],A[2][2],A[1][2],A[2][3],A[1][3],A[2][4],A[1][4]])\n",
    "                d = {\"season\":season, \"month\":month, \"away_team\":away_team, \"home_team\":hometeam, \"1st_away\":A[2][1], \"1st_home\":A[1][1],\"2st_away\":A[2][2], \"2st_home\":A[1][2],\"3st_away\":A[2][3], \"3st_home\":A[1][3],\"4th_away\":A[2][4], \"4th_home\":A[1][4]}\n",
    "                df = pd.DataFrame(data=d, index=[\"rows\",])\n",
    "                df.drop_duplicates()\n",
    "                output_data = output_data.append(df)\n",
    "                #df.to_csv(df[\"away_team\"][0]+'_'+df[\"home_team\"][0]+'_'+df[\"month\"][0]+'_'+df[\"season\"][0]+' .csv')\n",
    "            else:\n",
    "                #whole_data.append([season,month,away_team,home_team,A[1][1],A[2][1],A[1][2],A[2][2],A[1][3],A[2][3],A[1][4],A[2][4]])\n",
    "                d = {\"season\":season, \"month\":month, \"away_team\":away_team, \"home_team\":hometeam, \"1st_away\":A[1][1], \"1st_home\":A[2][1],\"2st_away\":A[1][2], \"2st_home\":A[2][2],\"3st_away\":A[1][3], \"3st_home\":A[2][3],\"4th_away\":A[1][4], \"4th_home\":A[2][4]}\n",
    "                df = pd.DataFrame(data=d, index=[\"rows\",])\n",
    "                df.drop_duplicates()\n",
    "                output_data = output_data.append(df)\n",
    "                #df.to_csv(df[\"away_team\"][0]+'_'+df[\"home_team\"][0]+'_'+df[\"month\"][0]+'_'+df[\"season\"][0]+' .csv')\n",
    "            if len(output_data) == 0:\n",
    "                print \"output_data is none!\"\n",
    "print len(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_data.to_csv('NBA_2014_2017_Data_1.csv') "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
